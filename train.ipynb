{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778fcb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13134508655221177412\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7803502592\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9213879825608676633\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c5c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "from model.Model import Model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48db759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model complete!\n"
     ]
    }
   ],
   "source": [
    "model = Model(model = keras.applications.ResNet50) # 매개변수에 keras에서 제공해주는 모델을 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd2d6c",
   "metadata": {},
   "source": [
    "위 모델을 수정하고 싶으시면 model 폴더의 Model에서 모델을 추가하거나 빼시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ea0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbe4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_1[0][0]']                \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, None, None,   256         ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, None, None,   0           ['conv1_bn[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_relu[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, None, None,   4160        ['pool1_pool[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['pool1_pool[0][0]']             \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, None, None,   0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                256)                              'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, None, None,   0           ['conv2_block1_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block1_out[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n",
      "                                256)                              'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, None, None,   0           ['conv2_block2_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block2_out[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, None, None,   0           ['conv2_block2_out[0][0]',       \n",
      "                                256)                              'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, None, None,   0           ['conv2_block3_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, None, None,   32896       ['conv2_block3_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv2_block3_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, None, None,   0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                512)                              'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, None, None,   0           ['conv3_block1_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block1_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n",
      "                                512)                              'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, None, None,   0           ['conv3_block2_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block2_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n",
      "                                512)                              'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, None, None,   0           ['conv3_block3_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block3_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, None, None,   0           ['conv3_block3_out[0][0]',       \n",
      "                                512)                              'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, None, None,   0           ['conv3_block4_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, None, None,   131328      ['conv3_block4_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv3_block4_out[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, None, None,   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                1024)                             'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, None, None,   0           ['conv4_block1_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block1_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n",
      "                                1024)                             'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, None, None,   0           ['conv4_block2_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block2_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n",
      "                                1024)                             'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, None, None,   0           ['conv4_block3_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block3_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n",
      "                                1024)                             'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, None, None,   0           ['conv4_block4_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block4_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n",
      "                                1024)                             'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, None, None,   0           ['conv4_block5_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block5_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, None, None,   0           ['conv4_block5_out[0][0]',       \n",
      "                                1024)                             'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, None, None,   0           ['conv4_block6_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, None, None,   524800      ['conv4_block6_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, None, None,   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                2048)                             'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, None, None,   0           ['conv5_block1_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block1_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n",
      "                                2048)                             'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, None, None,   0           ['conv5_block2_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block2_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n",
      "                                2048)                             'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, None, None,   0           ['conv5_block3_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            8196        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e700833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongjin\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 1.3338 - accuracy: 0.3242 - val_loss: 1.2436 - val_accuracy: 0.3397 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2445 - accuracy: 0.3523 - val_loss: 1.2320 - val_accuracy: 0.3699 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 47s 1s/step - loss: 1.2292 - accuracy: 0.3640 - val_loss: 1.2211 - val_accuracy: 0.3781 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.2227 - accuracy: 0.3832 - val_loss: 1.2256 - val_accuracy: 0.3753 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2242 - accuracy: 0.3558 - val_loss: 1.2192 - val_accuracy: 0.4137 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 1.2234 - accuracy: 0.3826 - val_loss: 1.2309 - val_accuracy: 0.3699 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2188 - accuracy: 0.3757 - val_loss: 1.2122 - val_accuracy: 0.3836 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 1.2251 - accuracy: 0.3736 - val_loss: 1.2088 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.2134 - accuracy: 0.4073 - val_loss: 1.2099 - val_accuracy: 0.4082 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2130 - accuracy: 0.3977 - val_loss: 1.2085 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 1.2245 - accuracy: 0.3798 - val_loss: 1.2174 - val_accuracy: 0.3781 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2186 - accuracy: 0.4004 - val_loss: 1.1971 - val_accuracy: 0.4356 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 1.2147 - accuracy: 0.3846 - val_loss: 1.2098 - val_accuracy: 0.4575 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.2128 - accuracy: 0.4052 - val_loss: 1.2112 - val_accuracy: 0.4137 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 1.2176 - accuracy: 0.3990 - val_loss: 1.2079 - val_accuracy: 0.4493 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2089 - accuracy: 0.3977 - val_loss: 1.1932 - val_accuracy: 0.4438 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2024 - accuracy: 0.4265 - val_loss: 1.1931 - val_accuracy: 0.4521 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 1.2140 - accuracy: 0.3970 - val_loss: 1.2584 - val_accuracy: 0.3260 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.2060 - accuracy: 0.4217 - val_loss: 1.1938 - val_accuracy: 0.4603 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 1.2054 - accuracy: 0.4341 - val_loss: 1.2015 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.2163 - accuracy: 0.3915 - val_loss: 1.1940 - val_accuracy: 0.4274 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 45s 987ms/step - loss: 1.2085 - accuracy: 0.3970 - val_loss: 1.2109 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.2013 - accuracy: 0.4279 - val_loss: 1.1983 - val_accuracy: 0.4301 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 1.1947 - accuracy: 0.4485 - val_loss: 1.1945 - val_accuracy: 0.4219 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1968 - accuracy: 0.4251 - val_loss: 1.1947 - val_accuracy: 0.4603 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 1.1965 - accuracy: 0.4348 - val_loss: 1.1895 - val_accuracy: 0.4630 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1941 - accuracy: 0.4348 - val_loss: 1.2121 - val_accuracy: 0.4027 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.2046 - accuracy: 0.4011 - val_loss: 1.1842 - val_accuracy: 0.4466 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1945 - accuracy: 0.4348 - val_loss: 1.2104 - val_accuracy: 0.4110 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1995 - accuracy: 0.4245 - val_loss: 1.1927 - val_accuracy: 0.4082 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 1.1889 - accuracy: 0.4313 - val_loss: 1.1887 - val_accuracy: 0.4438 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.1937 - accuracy: 0.4389 - val_loss: 1.1925 - val_accuracy: 0.4603 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.2007 - accuracy: 0.4327 - val_loss: 1.2013 - val_accuracy: 0.4082 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 1.1892 - accuracy: 0.4231 - val_loss: 1.1833 - val_accuracy: 0.4712 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 1.1912 - accuracy: 0.4279 - val_loss: 1.1939 - val_accuracy: 0.4521 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.1955 - accuracy: 0.4409 - val_loss: 1.1859 - val_accuracy: 0.4685 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.1937 - accuracy: 0.4492 - val_loss: 1.1834 - val_accuracy: 0.4658 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 1.1863 - accuracy: 0.4471 - val_loss: 1.1974 - val_accuracy: 0.4301 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.1918 - accuracy: 0.4382 - val_loss: 1.1889 - val_accuracy: 0.4082 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 1.1878 - accuracy: 0.4430 - val_loss: 1.1833 - val_accuracy: 0.4740 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1930 - accuracy: 0.4396 - val_loss: 1.1836 - val_accuracy: 0.4712 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 1.1925 - accuracy: 0.4451 - val_loss: 1.1821 - val_accuracy: 0.4712 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1914 - accuracy: 0.4437 - val_loss: 1.1844 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1872 - accuracy: 0.4437 - val_loss: 1.1869 - val_accuracy: 0.4795 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1876 - accuracy: 0.4609 - val_loss: 1.1840 - val_accuracy: 0.4548 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 45s 987ms/step - loss: 1.1838 - accuracy: 0.4416 - val_loss: 1.1823 - val_accuracy: 0.4575 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 1.1874 - accuracy: 0.4444 - val_loss: 1.1846 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 1.1903 - accuracy: 0.4567 - val_loss: 1.1819 - val_accuracy: 0.4740 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 1.1847 - accuracy: 0.4595 - val_loss: 1.1829 - val_accuracy: 0.4740 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 1.1860 - accuracy: 0.4629 - val_loss: 1.1843 - val_accuracy: 0.4767 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 46s 1s/step - loss: 1.1835 - accuracy: 0.4725 - val_loss: 1.1811 - val_accuracy: 0.4767 - lr: 6.2500e-05\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1855 - accuracy: 0.4526 - val_loss: 1.1828 - val_accuracy: 0.4767 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 45s 988ms/step - loss: 1.1828 - accuracy: 0.4732 - val_loss: 1.1837 - val_accuracy: 0.4685 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 1.1841 - accuracy: 0.4464 - val_loss: 1.1834 - val_accuracy: 0.4822 - lr: 6.2500e-05\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1864 - accuracy: 0.4609 - val_loss: 1.1820 - val_accuracy: 0.4767 - lr: 6.2500e-05\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 1.1922 - accuracy: 0.4437 - val_loss: 1.1828 - val_accuracy: 0.4767 - lr: 6.2500e-05\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 1.1874 - accuracy: 0.4409 - val_loss: 1.1821 - val_accuracy: 0.4712 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 1.1898 - accuracy: 0.4430 - val_loss: 1.1832 - val_accuracy: 0.4767 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 1.1818 - accuracy: 0.4595 - val_loss: 1.1815 - val_accuracy: 0.4740 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 1.1892 - accuracy: 0.4567 - val_loss: 1.1828 - val_accuracy: 0.4658 - lr: 3.1250e-05\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 1.1899 - accuracy: 0.4567 - val_loss: 1.1816 - val_accuracy: 0.4740 - lr: 3.1250e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a27196970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import train\n",
    "\"\"\"\n",
    "콜백 & 로그\n",
    "    log        : 폴더에 에포크마다 모델이 저장되고 early stopping 됩니다.\n",
    "    callback   : 콜백함수를 수정하고 싶으시면 model 폴더에서 callback.py에 들어가셔서 수정하시면 됩니다.\n",
    "\n",
    "\n",
    "매개변수\n",
    "    model      : 모델을 넣으면 됩니다.\n",
    "    optimizer  : 옵티마이저를 지정해서 넣을 수 있습니다.\n",
    "    dir_name   : log 폴더에 저장될 모델의 log 폴더의 이름을 지정할 수 있고 None이 들어간다면 학습을 시작하는 시간으로 폴더이름이 정해집니다.\n",
    "    model_name : 모델이 저장될 이름을 뜻합니다.\n",
    "\"\"\"\n",
    "train(model, epochs = 100, optimizer = keras.optimizers.Adam(), dir_name = \"./logs/FirstTrain\", \n",
    "      model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4016e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1_conv\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 pool1_pad\n",
      "6 pool1_pool\n",
      "7 conv2_block1_1_conv\n",
      "8 conv2_block1_1_bn\n",
      "9 conv2_block1_1_relu\n",
      "10 conv2_block1_2_conv\n",
      "11 conv2_block1_2_bn\n",
      "12 conv2_block1_2_relu\n",
      "13 conv2_block1_0_conv\n",
      "14 conv2_block1_3_conv\n",
      "15 conv2_block1_0_bn\n",
      "16 conv2_block1_3_bn\n",
      "17 conv2_block1_add\n",
      "18 conv2_block1_out\n",
      "19 conv2_block2_1_conv\n",
      "20 conv2_block2_1_bn\n",
      "21 conv2_block2_1_relu\n",
      "22 conv2_block2_2_conv\n",
      "23 conv2_block2_2_bn\n",
      "24 conv2_block2_2_relu\n",
      "25 conv2_block2_3_conv\n",
      "26 conv2_block2_3_bn\n",
      "27 conv2_block2_add\n",
      "28 conv2_block2_out\n",
      "29 conv2_block3_1_conv\n",
      "30 conv2_block3_1_bn\n",
      "31 conv2_block3_1_relu\n",
      "32 conv2_block3_2_conv\n",
      "33 conv2_block3_2_bn\n",
      "34 conv2_block3_2_relu\n",
      "35 conv2_block3_3_conv\n",
      "36 conv2_block3_3_bn\n",
      "37 conv2_block3_add\n",
      "38 conv2_block3_out\n",
      "39 conv3_block1_1_conv\n",
      "40 conv3_block1_1_bn\n",
      "41 conv3_block1_1_relu\n",
      "42 conv3_block1_2_conv\n",
      "43 conv3_block1_2_bn\n",
      "44 conv3_block1_2_relu\n",
      "45 conv3_block1_0_conv\n",
      "46 conv3_block1_3_conv\n",
      "47 conv3_block1_0_bn\n",
      "48 conv3_block1_3_bn\n",
      "49 conv3_block1_add\n",
      "50 conv3_block1_out\n",
      "51 conv3_block2_1_conv\n",
      "52 conv3_block2_1_bn\n",
      "53 conv3_block2_1_relu\n",
      "54 conv3_block2_2_conv\n",
      "55 conv3_block2_2_bn\n",
      "56 conv3_block2_2_relu\n",
      "57 conv3_block2_3_conv\n",
      "58 conv3_block2_3_bn\n",
      "59 conv3_block2_add\n",
      "60 conv3_block2_out\n",
      "61 conv3_block3_1_conv\n",
      "62 conv3_block3_1_bn\n",
      "63 conv3_block3_1_relu\n",
      "64 conv3_block3_2_conv\n",
      "65 conv3_block3_2_bn\n",
      "66 conv3_block3_2_relu\n",
      "67 conv3_block3_3_conv\n",
      "68 conv3_block3_3_bn\n",
      "69 conv3_block3_add\n",
      "70 conv3_block3_out\n",
      "71 conv3_block4_1_conv\n",
      "72 conv3_block4_1_bn\n",
      "73 conv3_block4_1_relu\n",
      "74 conv3_block4_2_conv\n",
      "75 conv3_block4_2_bn\n",
      "76 conv3_block4_2_relu\n",
      "77 conv3_block4_3_conv\n",
      "78 conv3_block4_3_bn\n",
      "79 conv3_block4_add\n",
      "80 conv3_block4_out\n",
      "81 conv4_block1_1_conv\n",
      "82 conv4_block1_1_bn\n",
      "83 conv4_block1_1_relu\n",
      "84 conv4_block1_2_conv\n",
      "85 conv4_block1_2_bn\n",
      "86 conv4_block1_2_relu\n",
      "87 conv4_block1_0_conv\n",
      "88 conv4_block1_3_conv\n",
      "89 conv4_block1_0_bn\n",
      "90 conv4_block1_3_bn\n",
      "91 conv4_block1_add\n",
      "92 conv4_block1_out\n",
      "93 conv4_block2_1_conv\n",
      "94 conv4_block2_1_bn\n",
      "95 conv4_block2_1_relu\n",
      "96 conv4_block2_2_conv\n",
      "97 conv4_block2_2_bn\n",
      "98 conv4_block2_2_relu\n",
      "99 conv4_block2_3_conv\n",
      "100 conv4_block2_3_bn\n",
      "101 conv4_block2_add\n",
      "102 conv4_block2_out\n",
      "103 conv4_block3_1_conv\n",
      "104 conv4_block3_1_bn\n",
      "105 conv4_block3_1_relu\n",
      "106 conv4_block3_2_conv\n",
      "107 conv4_block3_2_bn\n",
      "108 conv4_block3_2_relu\n",
      "109 conv4_block3_3_conv\n",
      "110 conv4_block3_3_bn\n",
      "111 conv4_block3_add\n",
      "112 conv4_block3_out\n",
      "113 conv4_block4_1_conv\n",
      "114 conv4_block4_1_bn\n",
      "115 conv4_block4_1_relu\n",
      "116 conv4_block4_2_conv\n",
      "117 conv4_block4_2_bn\n",
      "118 conv4_block4_2_relu\n",
      "119 conv4_block4_3_conv\n",
      "120 conv4_block4_3_bn\n",
      "121 conv4_block4_add\n",
      "122 conv4_block4_out\n",
      "123 conv4_block5_1_conv\n",
      "124 conv4_block5_1_bn\n",
      "125 conv4_block5_1_relu\n",
      "126 conv4_block5_2_conv\n",
      "127 conv4_block5_2_bn\n",
      "128 conv4_block5_2_relu\n",
      "129 conv4_block5_3_conv\n",
      "130 conv4_block5_3_bn\n",
      "131 conv4_block5_add\n",
      "132 conv4_block5_out\n",
      "133 conv4_block6_1_conv\n",
      "134 conv4_block6_1_bn\n",
      "135 conv4_block6_1_relu\n",
      "136 conv4_block6_2_conv\n",
      "137 conv4_block6_2_bn\n",
      "138 conv4_block6_2_relu\n",
      "139 conv4_block6_3_conv\n",
      "140 conv4_block6_3_bn\n",
      "141 conv4_block6_add\n",
      "142 conv4_block6_out\n",
      "143 conv5_block1_1_conv\n",
      "144 conv5_block1_1_bn\n",
      "145 conv5_block1_1_relu\n",
      "146 conv5_block1_2_conv\n",
      "147 conv5_block1_2_bn\n",
      "148 conv5_block1_2_relu\n",
      "149 conv5_block1_0_conv\n",
      "150 conv5_block1_3_conv\n",
      "151 conv5_block1_0_bn\n",
      "152 conv5_block1_3_bn\n",
      "153 conv5_block1_add\n",
      "154 conv5_block1_out\n",
      "155 conv5_block2_1_conv\n",
      "156 conv5_block2_1_bn\n",
      "157 conv5_block2_1_relu\n",
      "158 conv5_block2_2_conv\n",
      "159 conv5_block2_2_bn\n",
      "160 conv5_block2_2_relu\n",
      "161 conv5_block2_3_conv\n",
      "162 conv5_block2_3_bn\n",
      "163 conv5_block2_add\n",
      "164 conv5_block2_out\n",
      "165 conv5_block3_1_conv\n",
      "166 conv5_block3_1_bn\n",
      "167 conv5_block3_1_relu\n",
      "168 conv5_block3_2_conv\n",
      "169 conv5_block3_2_bn\n",
      "170 conv5_block3_2_relu\n",
      "171 conv5_block3_3_conv\n",
      "172 conv5_block3_3_bn\n",
      "173 conv5_block3_add\n",
      "174 conv5_block3_out\n",
      "175 global_average_pooling2d\n",
      "176 dense\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec7a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/FirstTrain/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0166d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv5를 모두 품\n",
    "for layer in model.layers[143:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37633bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 49s 1s/step - loss: 1.6713 - accuracy: 0.3716 - val_loss: 1.3294 - val_accuracy: 0.3370 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 1.2198 - accuracy: 0.4306 - val_loss: 1.2958 - val_accuracy: 0.3425 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 1.2427 - accuracy: 0.4327 - val_loss: 1.2482 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 1.2589 - accuracy: 0.4100 - val_loss: 1.3189 - val_accuracy: 0.4219 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 1.2317 - accuracy: 0.4368 - val_loss: 1.2157 - val_accuracy: 0.4548 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 1.2006 - accuracy: 0.4595 - val_loss: 1.2672 - val_accuracy: 0.4548 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.2355 - accuracy: 0.4574 - val_loss: 1.2634 - val_accuracy: 0.4712 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 45s 987ms/step - loss: 1.1417 - accuracy: 0.4815 - val_loss: 1.1902 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.1448 - accuracy: 0.4897 - val_loss: 1.7386 - val_accuracy: 0.4192 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 1.1305 - accuracy: 0.4904 - val_loss: 1.1568 - val_accuracy: 0.4904 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 1.1304 - accuracy: 0.5089 - val_loss: 1.1054 - val_accuracy: 0.5178 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.1546 - accuracy: 0.4938 - val_loss: 1.1219 - val_accuracy: 0.5315 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.1703 - accuracy: 0.4746 - val_loss: 1.2083 - val_accuracy: 0.4822 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 1.1288 - accuracy: 0.5055 - val_loss: 2.0990 - val_accuracy: 0.3397 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 45s 968ms/step - loss: 1.1541 - accuracy: 0.4849 - val_loss: 1.2592 - val_accuracy: 0.4795 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 1.1852 - accuracy: 0.4718 - val_loss: 1.2848 - val_accuracy: 0.4877 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 1.1335 - accuracy: 0.4945 - val_loss: 1.2843 - val_accuracy: 0.4986 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 1.0585 - accuracy: 0.5481 - val_loss: 1.1891 - val_accuracy: 0.4849 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.0857 - accuracy: 0.5165 - val_loss: 1.1426 - val_accuracy: 0.5014 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 1.0677 - accuracy: 0.5337 - val_loss: 2.1377 - val_accuracy: 0.3315 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 1.0593 - accuracy: 0.5543 - val_loss: 3.1531 - val_accuracy: 0.2932 - lr: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a30868400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 100, optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "      dir_name = \"./logs/SecondTrain\", model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa7a137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv4_block1_1_conv\n",
      "1 conv4_block1_1_bn\n",
      "2 conv4_block1_1_relu\n",
      "3 conv4_block1_2_conv\n",
      "4 conv4_block1_2_bn\n",
      "5 conv4_block1_2_relu\n",
      "6 conv4_block1_0_conv\n",
      "7 conv4_block1_3_conv\n",
      "8 conv4_block1_0_bn\n",
      "9 conv4_block1_3_bn\n",
      "10 conv4_block1_add\n",
      "11 conv4_block1_out\n",
      "12 conv4_block2_1_conv\n",
      "13 conv4_block2_1_bn\n",
      "14 conv4_block2_1_relu\n",
      "15 conv4_block2_2_conv\n",
      "16 conv4_block2_2_bn\n",
      "17 conv4_block2_2_relu\n",
      "18 conv4_block2_3_conv\n",
      "19 conv4_block2_3_bn\n",
      "20 conv4_block2_add\n",
      "21 conv4_block2_out\n",
      "22 conv4_block3_1_conv\n",
      "23 conv4_block3_1_bn\n",
      "24 conv4_block3_1_relu\n",
      "25 conv4_block3_2_conv\n",
      "26 conv4_block3_2_bn\n",
      "27 conv4_block3_2_relu\n",
      "28 conv4_block3_3_conv\n",
      "29 conv4_block3_3_bn\n",
      "30 conv4_block3_add\n",
      "31 conv4_block3_out\n",
      "32 conv4_block4_1_conv\n",
      "33 conv4_block4_1_bn\n",
      "34 conv4_block4_1_relu\n",
      "35 conv4_block4_2_conv\n",
      "36 conv4_block4_2_bn\n",
      "37 conv4_block4_2_relu\n",
      "38 conv4_block4_3_conv\n",
      "39 conv4_block4_3_bn\n",
      "40 conv4_block4_add\n",
      "41 conv4_block4_out\n",
      "42 conv4_block5_1_conv\n",
      "43 conv4_block5_1_bn\n",
      "44 conv4_block5_1_relu\n",
      "45 conv4_block5_2_conv\n",
      "46 conv4_block5_2_bn\n",
      "47 conv4_block5_2_relu\n",
      "48 conv4_block5_3_conv\n",
      "49 conv4_block5_3_bn\n",
      "50 conv4_block5_add\n",
      "51 conv4_block5_out\n",
      "52 conv4_block6_1_conv\n",
      "53 conv4_block6_1_bn\n",
      "54 conv4_block6_1_relu\n",
      "55 conv4_block6_2_conv\n",
      "56 conv4_block6_2_bn\n",
      "57 conv4_block6_2_relu\n",
      "58 conv4_block6_3_conv\n",
      "59 conv4_block6_3_bn\n",
      "60 conv4_block6_add\n",
      "61 conv4_block6_out\n",
      "62 conv5_block1_1_conv\n",
      "63 conv5_block1_1_bn\n",
      "64 conv5_block1_1_relu\n",
      "65 conv5_block1_2_conv\n",
      "66 conv5_block1_2_bn\n",
      "67 conv5_block1_2_relu\n",
      "68 conv5_block1_0_conv\n",
      "69 conv5_block1_3_conv\n",
      "70 conv5_block1_0_bn\n",
      "71 conv5_block1_3_bn\n",
      "72 conv5_block1_add\n",
      "73 conv5_block1_out\n",
      "74 conv5_block2_1_conv\n",
      "75 conv5_block2_1_bn\n",
      "76 conv5_block2_1_relu\n",
      "77 conv5_block2_2_conv\n",
      "78 conv5_block2_2_bn\n",
      "79 conv5_block2_2_relu\n",
      "80 conv5_block2_3_conv\n",
      "81 conv5_block2_3_bn\n",
      "82 conv5_block2_add\n",
      "83 conv5_block2_out\n",
      "84 conv5_block3_1_conv\n",
      "85 conv5_block3_1_bn\n",
      "86 conv5_block3_1_relu\n",
      "87 conv5_block3_2_conv\n",
      "88 conv5_block3_2_bn\n",
      "89 conv5_block3_2_relu\n",
      "90 conv5_block3_3_conv\n",
      "91 conv5_block3_3_bn\n",
      "92 conv5_block3_add\n",
      "93 conv5_block3_out\n",
      "94 global_average_pooling2d\n",
      "95 dense\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers[81:]):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b142a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/SecondTrain/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c054320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv4\n",
    "for layer in model.layers[81:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "944c964a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 49s 1s/step - loss: 1.6941 - accuracy: 0.3633 - val_loss: 1.4279 - val_accuracy: 0.3507 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 45s 983ms/step - loss: 1.2722 - accuracy: 0.4190 - val_loss: 1.2320 - val_accuracy: 0.4219 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 1.2698 - accuracy: 0.4389 - val_loss: 1.2057 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 45s 971ms/step - loss: 1.1803 - accuracy: 0.4753 - val_loss: 1.3006 - val_accuracy: 0.3507 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 45s 969ms/step - loss: 1.1228 - accuracy: 0.5069 - val_loss: 1.8527 - val_accuracy: 0.2849 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 45s 969ms/step - loss: 1.1297 - accuracy: 0.4924 - val_loss: 1.7716 - val_accuracy: 0.3781 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 45s 967ms/step - loss: 1.1071 - accuracy: 0.5206 - val_loss: 1.3175 - val_accuracy: 0.3836 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 45s 967ms/step - loss: 1.0916 - accuracy: 0.5481 - val_loss: 1.7871 - val_accuracy: 0.3671 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 1.0354 - accuracy: 0.5495 - val_loss: 1.3933 - val_accuracy: 0.4411 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.9861 - accuracy: 0.5859 - val_loss: 1.9535 - val_accuracy: 0.3781 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 45s 967ms/step - loss: 0.9569 - accuracy: 0.5920 - val_loss: 1.8025 - val_accuracy: 0.4548 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 45s 971ms/step - loss: 0.9558 - accuracy: 0.6126 - val_loss: 3.2984 - val_accuracy: 0.3397 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.9734 - accuracy: 0.5845 - val_loss: 2.4240 - val_accuracy: 0.4466 - lr: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a8276d6d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 100, optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "      dir_name = \"./logs/ThirdTrain\", model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325bccab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1_conv\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 pool1_pad\n",
      "6 pool1_pool\n",
      "7 conv2_block1_1_conv\n",
      "8 conv2_block1_1_bn\n",
      "9 conv2_block1_1_relu\n",
      "10 conv2_block1_2_conv\n",
      "11 conv2_block1_2_bn\n",
      "12 conv2_block1_2_relu\n",
      "13 conv2_block1_0_conv\n",
      "14 conv2_block1_3_conv\n",
      "15 conv2_block1_0_bn\n",
      "16 conv2_block1_3_bn\n",
      "17 conv2_block1_add\n",
      "18 conv2_block1_out\n",
      "19 conv2_block2_1_conv\n",
      "20 conv2_block2_1_bn\n",
      "21 conv2_block2_1_relu\n",
      "22 conv2_block2_2_conv\n",
      "23 conv2_block2_2_bn\n",
      "24 conv2_block2_2_relu\n",
      "25 conv2_block2_3_conv\n",
      "26 conv2_block2_3_bn\n",
      "27 conv2_block2_add\n",
      "28 conv2_block2_out\n",
      "29 conv2_block3_1_conv\n",
      "30 conv2_block3_1_bn\n",
      "31 conv2_block3_1_relu\n",
      "32 conv2_block3_2_conv\n",
      "33 conv2_block3_2_bn\n",
      "34 conv2_block3_2_relu\n",
      "35 conv2_block3_3_conv\n",
      "36 conv2_block3_3_bn\n",
      "37 conv2_block3_add\n",
      "38 conv2_block3_out\n",
      "39 conv3_block1_1_conv\n",
      "40 conv3_block1_1_bn\n",
      "41 conv3_block1_1_relu\n",
      "42 conv3_block1_2_conv\n",
      "43 conv3_block1_2_bn\n",
      "44 conv3_block1_2_relu\n",
      "45 conv3_block1_0_conv\n",
      "46 conv3_block1_3_conv\n",
      "47 conv3_block1_0_bn\n",
      "48 conv3_block1_3_bn\n",
      "49 conv3_block1_add\n",
      "50 conv3_block1_out\n",
      "51 conv3_block2_1_conv\n",
      "52 conv3_block2_1_bn\n",
      "53 conv3_block2_1_relu\n",
      "54 conv3_block2_2_conv\n",
      "55 conv3_block2_2_bn\n",
      "56 conv3_block2_2_relu\n",
      "57 conv3_block2_3_conv\n",
      "58 conv3_block2_3_bn\n",
      "59 conv3_block2_add\n",
      "60 conv3_block2_out\n",
      "61 conv3_block3_1_conv\n",
      "62 conv3_block3_1_bn\n",
      "63 conv3_block3_1_relu\n",
      "64 conv3_block3_2_conv\n",
      "65 conv3_block3_2_bn\n",
      "66 conv3_block3_2_relu\n",
      "67 conv3_block3_3_conv\n",
      "68 conv3_block3_3_bn\n",
      "69 conv3_block3_add\n",
      "70 conv3_block3_out\n",
      "71 conv3_block4_1_conv\n",
      "72 conv3_block4_1_bn\n",
      "73 conv3_block4_1_relu\n",
      "74 conv3_block4_2_conv\n",
      "75 conv3_block4_2_bn\n",
      "76 conv3_block4_2_relu\n",
      "77 conv3_block4_3_conv\n",
      "78 conv3_block4_3_bn\n",
      "79 conv3_block4_add\n",
      "80 conv3_block4_out\n",
      "81 conv4_block1_1_conv\n",
      "82 conv4_block1_1_bn\n",
      "83 conv4_block1_1_relu\n",
      "84 conv4_block1_2_conv\n",
      "85 conv4_block1_2_bn\n",
      "86 conv4_block1_2_relu\n",
      "87 conv4_block1_0_conv\n",
      "88 conv4_block1_3_conv\n",
      "89 conv4_block1_0_bn\n",
      "90 conv4_block1_3_bn\n",
      "91 conv4_block1_add\n",
      "92 conv4_block1_out\n",
      "93 conv4_block2_1_conv\n",
      "94 conv4_block2_1_bn\n",
      "95 conv4_block2_1_relu\n",
      "96 conv4_block2_2_conv\n",
      "97 conv4_block2_2_bn\n",
      "98 conv4_block2_2_relu\n",
      "99 conv4_block2_3_conv\n",
      "100 conv4_block2_3_bn\n",
      "101 conv4_block2_add\n",
      "102 conv4_block2_out\n",
      "103 conv4_block3_1_conv\n",
      "104 conv4_block3_1_bn\n",
      "105 conv4_block3_1_relu\n",
      "106 conv4_block3_2_conv\n",
      "107 conv4_block3_2_bn\n",
      "108 conv4_block3_2_relu\n",
      "109 conv4_block3_3_conv\n",
      "110 conv4_block3_3_bn\n",
      "111 conv4_block3_add\n",
      "112 conv4_block3_out\n",
      "113 conv4_block4_1_conv\n",
      "114 conv4_block4_1_bn\n",
      "115 conv4_block4_1_relu\n",
      "116 conv4_block4_2_conv\n",
      "117 conv4_block4_2_bn\n",
      "118 conv4_block4_2_relu\n",
      "119 conv4_block4_3_conv\n",
      "120 conv4_block4_3_bn\n",
      "121 conv4_block4_add\n",
      "122 conv4_block4_out\n",
      "123 conv4_block5_1_conv\n",
      "124 conv4_block5_1_bn\n",
      "125 conv4_block5_1_relu\n",
      "126 conv4_block5_2_conv\n",
      "127 conv4_block5_2_bn\n",
      "128 conv4_block5_2_relu\n",
      "129 conv4_block5_3_conv\n",
      "130 conv4_block5_3_bn\n",
      "131 conv4_block5_add\n",
      "132 conv4_block5_out\n",
      "133 conv4_block6_1_conv\n",
      "134 conv4_block6_1_bn\n",
      "135 conv4_block6_1_relu\n",
      "136 conv4_block6_2_conv\n",
      "137 conv4_block6_2_bn\n",
      "138 conv4_block6_2_relu\n",
      "139 conv4_block6_3_conv\n",
      "140 conv4_block6_3_bn\n",
      "141 conv4_block6_add\n",
      "142 conv4_block6_out\n",
      "143 conv5_block1_1_conv\n",
      "144 conv5_block1_1_bn\n",
      "145 conv5_block1_1_relu\n",
      "146 conv5_block1_2_conv\n",
      "147 conv5_block1_2_bn\n",
      "148 conv5_block1_2_relu\n",
      "149 conv5_block1_0_conv\n",
      "150 conv5_block1_3_conv\n",
      "151 conv5_block1_0_bn\n",
      "152 conv5_block1_3_bn\n",
      "153 conv5_block1_add\n",
      "154 conv5_block1_out\n",
      "155 conv5_block2_1_conv\n",
      "156 conv5_block2_1_bn\n",
      "157 conv5_block2_1_relu\n",
      "158 conv5_block2_2_conv\n",
      "159 conv5_block2_2_bn\n",
      "160 conv5_block2_2_relu\n",
      "161 conv5_block2_3_conv\n",
      "162 conv5_block2_3_bn\n",
      "163 conv5_block2_add\n",
      "164 conv5_block2_out\n",
      "165 conv5_block3_1_conv\n",
      "166 conv5_block3_1_bn\n",
      "167 conv5_block3_1_relu\n",
      "168 conv5_block3_2_conv\n",
      "169 conv5_block3_2_bn\n",
      "170 conv5_block3_2_relu\n",
      "171 conv5_block3_3_conv\n",
      "172 conv5_block3_3_bn\n",
      "173 conv5_block3_add\n",
      "174 conv5_block3_out\n",
      "175 global_average_pooling2d\n",
      "176 dense\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a62e62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/ThirdTrain/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da34dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 3\n",
    "for layer in model.layers[39:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99ab8d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 1.1730 - accuracy: 0.5405 - val_loss: 4.7194 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.5665 - accuracy: 0.8077 - val_loss: 7.3839 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.5300 - accuracy: 0.8310 - val_loss: 9.2724 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.4050 - accuracy: 0.8723 - val_loss: 9.6336 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.4114 - accuracy: 0.8633 - val_loss: 9.5068 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.3291 - accuracy: 0.8846 - val_loss: 8.6127 - val_accuracy: 0.2822 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.2868 - accuracy: 0.9093 - val_loss: 8.8610 - val_accuracy: 0.2822 - lr: 5.0000e-05\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.2061 - accuracy: 0.9375 - val_loss: 6.2411 - val_accuracy: 0.3151 - lr: 5.0000e-05\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.1967 - accuracy: 0.9320 - val_loss: 5.3222 - val_accuracy: 0.3945 - lr: 5.0000e-05\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.1794 - accuracy: 0.9437 - val_loss: 5.0132 - val_accuracy: 0.4301 - lr: 5.0000e-05\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1739 - accuracy: 0.9437 - val_loss: 3.7606 - val_accuracy: 0.4877 - lr: 5.0000e-05\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1450 - accuracy: 0.9471 - val_loss: 2.3248 - val_accuracy: 0.6219 - lr: 5.0000e-05\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1449 - accuracy: 0.9499 - val_loss: 2.2425 - val_accuracy: 0.6658 - lr: 5.0000e-05\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1377 - accuracy: 0.9526 - val_loss: 0.8729 - val_accuracy: 0.8411 - lr: 5.0000e-05\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1536 - accuracy: 0.9485 - val_loss: 0.9918 - val_accuracy: 0.8247 - lr: 5.0000e-05\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1290 - accuracy: 0.9574 - val_loss: 0.5082 - val_accuracy: 0.8767 - lr: 5.0000e-05\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.1136 - accuracy: 0.9560 - val_loss: 0.7154 - val_accuracy: 0.8356 - lr: 5.0000e-05\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1316 - accuracy: 0.9547 - val_loss: 0.3013 - val_accuracy: 0.9205 - lr: 5.0000e-05\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1056 - accuracy: 0.9574 - val_loss: 0.4230 - val_accuracy: 0.9151 - lr: 5.0000e-05\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.4276 - val_accuracy: 0.9068 - lr: 5.0000e-05\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.0917 - accuracy: 0.9712 - val_loss: 0.4603 - val_accuracy: 0.9014 - lr: 5.0000e-05\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.0912 - accuracy: 0.9691 - val_loss: 0.4491 - val_accuracy: 0.8904 - lr: 5.0000e-05\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.3840 - val_accuracy: 0.8904 - lr: 5.0000e-05\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0654 - accuracy: 0.9753 - val_loss: 0.3539 - val_accuracy: 0.9233 - lr: 2.5000e-05\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.3869 - val_accuracy: 0.9315 - lr: 2.5000e-05\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.4168 - val_accuracy: 0.9205 - lr: 2.5000e-05\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0440 - accuracy: 0.9876 - val_loss: 0.3547 - val_accuracy: 0.9315 - lr: 2.5000e-05\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.3476 - val_accuracy: 0.9260 - lr: 2.5000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b14721a30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-4),\n",
    "      dir_name = \"./logs/Fourth_train\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a2606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f0f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36068a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de5d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/Fourth_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "050a7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37c7512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 True\n",
      "1 conv1_pad False\n",
      "2 conv1_conv False\n",
      "3 conv1_bn False\n",
      "4 conv1_relu False\n",
      "5 pool1_pad False\n",
      "6 pool1_pool False\n",
      "7 conv2_block1_1_conv False\n",
      "8 conv2_block1_1_bn False\n",
      "9 conv2_block1_1_relu False\n",
      "10 conv2_block1_2_conv False\n",
      "11 conv2_block1_2_bn False\n",
      "12 conv2_block1_2_relu False\n",
      "13 conv2_block1_0_conv False\n",
      "14 conv2_block1_3_conv False\n",
      "15 conv2_block1_0_bn False\n",
      "16 conv2_block1_3_bn False\n",
      "17 conv2_block1_add False\n",
      "18 conv2_block1_out False\n",
      "19 conv2_block2_1_conv True\n",
      "20 conv2_block2_1_bn True\n",
      "21 conv2_block2_1_relu True\n",
      "22 conv2_block2_2_conv True\n",
      "23 conv2_block2_2_bn True\n",
      "24 conv2_block2_2_relu True\n",
      "25 conv2_block2_3_conv True\n",
      "26 conv2_block2_3_bn True\n",
      "27 conv2_block2_add True\n",
      "28 conv2_block2_out True\n",
      "29 conv2_block3_1_conv True\n",
      "30 conv2_block3_1_bn True\n",
      "31 conv2_block3_1_relu True\n",
      "32 conv2_block3_2_conv True\n",
      "33 conv2_block3_2_bn True\n",
      "34 conv2_block3_2_relu True\n",
      "35 conv2_block3_3_conv True\n",
      "36 conv2_block3_3_bn True\n",
      "37 conv2_block3_add True\n",
      "38 conv2_block3_out True\n",
      "39 conv3_block1_1_conv True\n",
      "40 conv3_block1_1_bn True\n",
      "41 conv3_block1_1_relu True\n",
      "42 conv3_block1_2_conv True\n",
      "43 conv3_block1_2_bn True\n",
      "44 conv3_block1_2_relu True\n",
      "45 conv3_block1_0_conv True\n",
      "46 conv3_block1_3_conv True\n",
      "47 conv3_block1_0_bn True\n",
      "48 conv3_block1_3_bn True\n",
      "49 conv3_block1_add True\n",
      "50 conv3_block1_out True\n",
      "51 conv3_block2_1_conv True\n",
      "52 conv3_block2_1_bn True\n",
      "53 conv3_block2_1_relu True\n",
      "54 conv3_block2_2_conv True\n",
      "55 conv3_block2_2_bn True\n",
      "56 conv3_block2_2_relu True\n",
      "57 conv3_block2_3_conv True\n",
      "58 conv3_block2_3_bn True\n",
      "59 conv3_block2_add True\n",
      "60 conv3_block2_out True\n",
      "61 conv3_block3_1_conv True\n",
      "62 conv3_block3_1_bn True\n",
      "63 conv3_block3_1_relu True\n",
      "64 conv3_block3_2_conv True\n",
      "65 conv3_block3_2_bn True\n",
      "66 conv3_block3_2_relu True\n",
      "67 conv3_block3_3_conv True\n",
      "68 conv3_block3_3_bn True\n",
      "69 conv3_block3_add True\n",
      "70 conv3_block3_out True\n",
      "71 conv3_block4_1_conv True\n",
      "72 conv3_block4_1_bn True\n",
      "73 conv3_block4_1_relu True\n",
      "74 conv3_block4_2_conv True\n",
      "75 conv3_block4_2_bn True\n",
      "76 conv3_block4_2_relu True\n",
      "77 conv3_block4_3_conv True\n",
      "78 conv3_block4_3_bn True\n",
      "79 conv3_block4_add True\n",
      "80 conv3_block4_out True\n",
      "81 conv4_block1_1_conv True\n",
      "82 conv4_block1_1_bn True\n",
      "83 conv4_block1_1_relu True\n",
      "84 conv4_block1_2_conv True\n",
      "85 conv4_block1_2_bn True\n",
      "86 conv4_block1_2_relu True\n",
      "87 conv4_block1_0_conv True\n",
      "88 conv4_block1_3_conv True\n",
      "89 conv4_block1_0_bn True\n",
      "90 conv4_block1_3_bn True\n",
      "91 conv4_block1_add True\n",
      "92 conv4_block1_out True\n",
      "93 conv4_block2_1_conv True\n",
      "94 conv4_block2_1_bn True\n",
      "95 conv4_block2_1_relu True\n",
      "96 conv4_block2_2_conv True\n",
      "97 conv4_block2_2_bn True\n",
      "98 conv4_block2_2_relu True\n",
      "99 conv4_block2_3_conv True\n",
      "100 conv4_block2_3_bn True\n",
      "101 conv4_block2_add True\n",
      "102 conv4_block2_out True\n",
      "103 conv4_block3_1_conv True\n",
      "104 conv4_block3_1_bn True\n",
      "105 conv4_block3_1_relu True\n",
      "106 conv4_block3_2_conv True\n",
      "107 conv4_block3_2_bn True\n",
      "108 conv4_block3_2_relu True\n",
      "109 conv4_block3_3_conv True\n",
      "110 conv4_block3_3_bn True\n",
      "111 conv4_block3_add True\n",
      "112 conv4_block3_out True\n",
      "113 conv4_block4_1_conv True\n",
      "114 conv4_block4_1_bn True\n",
      "115 conv4_block4_1_relu True\n",
      "116 conv4_block4_2_conv True\n",
      "117 conv4_block4_2_bn True\n",
      "118 conv4_block4_2_relu True\n",
      "119 conv4_block4_3_conv True\n",
      "120 conv4_block4_3_bn True\n",
      "121 conv4_block4_add True\n",
      "122 conv4_block4_out True\n",
      "123 conv4_block5_1_conv True\n",
      "124 conv4_block5_1_bn True\n",
      "125 conv4_block5_1_relu True\n",
      "126 conv4_block5_2_conv True\n",
      "127 conv4_block5_2_bn True\n",
      "128 conv4_block5_2_relu True\n",
      "129 conv4_block5_3_conv True\n",
      "130 conv4_block5_3_bn True\n",
      "131 conv4_block5_add True\n",
      "132 conv4_block5_out True\n",
      "133 conv4_block6_1_conv True\n",
      "134 conv4_block6_1_bn True\n",
      "135 conv4_block6_1_relu True\n",
      "136 conv4_block6_2_conv True\n",
      "137 conv4_block6_2_bn True\n",
      "138 conv4_block6_2_relu True\n",
      "139 conv4_block6_3_conv True\n",
      "140 conv4_block6_3_bn True\n",
      "141 conv4_block6_add True\n",
      "142 conv4_block6_out True\n",
      "143 conv5_block1_1_conv True\n",
      "144 conv5_block1_1_bn True\n",
      "145 conv5_block1_1_relu True\n",
      "146 conv5_block1_2_conv True\n",
      "147 conv5_block1_2_bn True\n",
      "148 conv5_block1_2_relu True\n",
      "149 conv5_block1_0_conv True\n",
      "150 conv5_block1_3_conv True\n",
      "151 conv5_block1_0_bn True\n",
      "152 conv5_block1_3_bn True\n",
      "153 conv5_block1_add True\n",
      "154 conv5_block1_out True\n",
      "155 conv5_block2_1_conv True\n",
      "156 conv5_block2_1_bn True\n",
      "157 conv5_block2_1_relu True\n",
      "158 conv5_block2_2_conv True\n",
      "159 conv5_block2_2_bn True\n",
      "160 conv5_block2_2_relu True\n",
      "161 conv5_block2_3_conv True\n",
      "162 conv5_block2_3_bn True\n",
      "163 conv5_block2_add True\n",
      "164 conv5_block2_out True\n",
      "165 conv5_block3_1_conv True\n",
      "166 conv5_block3_1_bn True\n",
      "167 conv5_block3_1_relu True\n",
      "168 conv5_block3_2_conv True\n",
      "169 conv5_block3_2_bn True\n",
      "170 conv5_block3_2_relu True\n",
      "171 conv5_block3_3_conv True\n",
      "172 conv5_block3_3_bn True\n",
      "173 conv5_block3_add True\n",
      "174 conv5_block3_out True\n",
      "175 global_average_pooling2d True\n",
      "176 dense True\n"
     ]
    }
   ],
   "source": [
    "# conv 2\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c87b25ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.8597 - accuracy: 0.6683 - val_loss: 2.8019 - val_accuracy: 0.2849 - lr: 1.0000e-05\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.5987 - accuracy: 0.7743 - val_loss: 3.0339 - val_accuracy: 0.2877 - lr: 1.0000e-05\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4930 - accuracy: 0.8128 - val_loss: 2.0717 - val_accuracy: 0.3425 - lr: 1.0000e-05\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4556 - accuracy: 0.8307 - val_loss: 1.9976 - val_accuracy: 0.4603 - lr: 1.0000e-05\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3705 - accuracy: 0.8665 - val_loss: 1.9416 - val_accuracy: 0.4493 - lr: 1.0000e-05\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3367 - accuracy: 0.8811 - val_loss: 1.6433 - val_accuracy: 0.4575 - lr: 1.0000e-05\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3317 - accuracy: 0.8727 - val_loss: 1.4751 - val_accuracy: 0.4521 - lr: 1.0000e-05\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.3024 - accuracy: 0.8933 - val_loss: 2.2176 - val_accuracy: 0.2932 - lr: 1.0000e-05\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2673 - accuracy: 0.9043 - val_loss: 2.7216 - val_accuracy: 0.2548 - lr: 1.0000e-05\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.2455 - accuracy: 0.9092 - val_loss: 2.7798 - val_accuracy: 0.2411 - lr: 1.0000e-05\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.2524 - accuracy: 0.9002 - val_loss: 3.1936 - val_accuracy: 0.2603 - lr: 1.0000e-05\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2192 - accuracy: 0.9226 - val_loss: 1.5416 - val_accuracy: 0.5178 - lr: 1.0000e-05\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2405 - accuracy: 0.9140 - val_loss: 0.5797 - val_accuracy: 0.7945 - lr: 5.0000e-06\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2048 - accuracy: 0.9253 - val_loss: 0.4641 - val_accuracy: 0.8438 - lr: 5.0000e-06\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2257 - accuracy: 0.9140 - val_loss: 0.4538 - val_accuracy: 0.8575 - lr: 5.0000e-06\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.1952 - accuracy: 0.9394 - val_loss: 0.4552 - val_accuracy: 0.8521 - lr: 5.0000e-06\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1862 - accuracy: 0.9332 - val_loss: 0.4662 - val_accuracy: 0.8466 - lr: 5.0000e-06\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1728 - accuracy: 0.9341 - val_loss: 0.4416 - val_accuracy: 0.8575 - lr: 5.0000e-06\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1661 - accuracy: 0.9394 - val_loss: 0.4679 - val_accuracy: 0.8575 - lr: 5.0000e-06\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1615 - accuracy: 0.9449 - val_loss: 0.4574 - val_accuracy: 0.8493 - lr: 5.0000e-06\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1686 - accuracy: 0.9401 - val_loss: 0.4382 - val_accuracy: 0.8575 - lr: 5.0000e-06\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1671 - accuracy: 0.9374 - val_loss: 0.4295 - val_accuracy: 0.8630 - lr: 5.0000e-06\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1762 - accuracy: 0.9339 - val_loss: 0.4242 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1743 - accuracy: 0.9314 - val_loss: 0.4352 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1653 - accuracy: 0.9456 - val_loss: 0.3862 - val_accuracy: 0.8575 - lr: 5.0000e-06\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.1446 - accuracy: 0.9484 - val_loss: 0.3916 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1446 - accuracy: 0.9490 - val_loss: 0.3842 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1521 - accuracy: 0.9401 - val_loss: 0.3749 - val_accuracy: 0.8603 - lr: 5.0000e-06\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1395 - accuracy: 0.9532 - val_loss: 0.3706 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1458 - accuracy: 0.9518 - val_loss: 0.3785 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.1304 - accuracy: 0.9560 - val_loss: 0.3736 - val_accuracy: 0.8795 - lr: 5.0000e-06\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.4052 - val_accuracy: 0.8712 - lr: 5.0000e-06\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.1480 - accuracy: 0.9525 - val_loss: 0.3956 - val_accuracy: 0.8712 - lr: 5.0000e-06\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1623 - accuracy: 0.9477 - val_loss: 0.3991 - val_accuracy: 0.8740 - lr: 5.0000e-06\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1277 - accuracy: 0.9599 - val_loss: 0.4050 - val_accuracy: 0.8740 - lr: 2.5000e-06\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1284 - accuracy: 0.9621 - val_loss: 0.4129 - val_accuracy: 0.8685 - lr: 2.5000e-06\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1098 - accuracy: 0.9635 - val_loss: 0.4054 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.1235 - accuracy: 0.9628 - val_loss: 0.3915 - val_accuracy: 0.8849 - lr: 2.5000e-06\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1176 - accuracy: 0.9546 - val_loss: 0.3920 - val_accuracy: 0.8849 - lr: 2.5000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf453b2df0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/Fifth_train\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65a0dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1308 - accuracy: 0.9546 - val_loss: 0.3743 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1367 - accuracy: 0.9573 - val_loss: 0.3804 - val_accuracy: 0.8740 - lr: 1.2500e-06\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.1283 - accuracy: 0.9573 - val_loss: 0.3837 - val_accuracy: 0.8685 - lr: 1.2500e-06\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1205 - accuracy: 0.9587 - val_loss: 0.3789 - val_accuracy: 0.8740 - lr: 1.2500e-06\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.1325 - accuracy: 0.9518 - val_loss: 0.3846 - val_accuracy: 0.8685 - lr: 1.2500e-06\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 0.1402 - accuracy: 0.9484 - val_loss: 0.3842 - val_accuracy: 0.8658 - lr: 1.2500e-06\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1369 - accuracy: 0.9553 - val_loss: 0.3891 - val_accuracy: 0.8603 - lr: 6.2500e-07\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.1412 - accuracy: 0.9463 - val_loss: 0.3902 - val_accuracy: 0.8630 - lr: 6.2500e-07\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.1202 - accuracy: 0.9628 - val_loss: 0.3894 - val_accuracy: 0.8630 - lr: 6.2500e-07\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.1363 - accuracy: 0.9518 - val_loss: 0.3927 - val_accuracy: 0.8685 - lr: 6.2500e-07\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 46s 984ms/step - loss: 0.1502 - accuracy: 0.9490 - val_loss: 0.3875 - val_accuracy: 0.8658 - lr: 6.2500e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf4571da60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.callbacks import callbacks\n",
    "from utils.utils import DataGenerator\n",
    "\n",
    "train, valid = DataGenerator()\n",
    "\n",
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=39,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/Fifth_train\"), batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b812b",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17418ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247add7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21592b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/Fourth_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70009d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a28c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks import callbacks\n",
    "from utils.utils import DataGenerator\n",
    "\n",
    "train, valid = DataGenerator()\n",
    "\n",
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=62,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/Fourth_train\"), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92b6111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1282 - accuracy: 0.9525 - val_loss: 0.3062 - val_accuracy: 0.9041 - lr: 6.2500e-07\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1401 - accuracy: 0.9525 - val_loss: 0.3064 - val_accuracy: 0.8986 - lr: 6.2500e-07\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1457 - accuracy: 0.9436 - val_loss: 0.3066 - val_accuracy: 0.9014 - lr: 6.2500e-07\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.1673 - accuracy: 0.9477 - val_loss: 0.3085 - val_accuracy: 0.9014 - lr: 6.2500e-07\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1251 - accuracy: 0.9608 - val_loss: 0.3095 - val_accuracy: 0.9014 - lr: 6.2500e-07\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1487 - accuracy: 0.9436 - val_loss: 0.3085 - val_accuracy: 0.9014 - lr: 6.2500e-07\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.1378 - accuracy: 0.9532 - val_loss: 0.3076 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.1334 - accuracy: 0.9573 - val_loss: 0.3055 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1356 - accuracy: 0.9546 - val_loss: 0.3053 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1337 - accuracy: 0.9587 - val_loss: 0.3047 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1125 - accuracy: 0.9642 - val_loss: 0.3057 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1393 - accuracy: 0.9573 - val_loss: 0.3064 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1275 - accuracy: 0.9566 - val_loss: 0.3054 - val_accuracy: 0.9041 - lr: 3.1250e-07\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1424 - accuracy: 0.9524 - val_loss: 0.3054 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.1253 - accuracy: 0.9615 - val_loss: 0.3051 - val_accuracy: 0.9014 - lr: 3.1250e-07\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1248 - accuracy: 0.9566 - val_loss: 0.3045 - val_accuracy: 0.9041 - lr: 1.5625e-07\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1478 - accuracy: 0.9504 - val_loss: 0.3046 - val_accuracy: 0.9041 - lr: 1.5625e-07\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1168 - accuracy: 0.9573 - val_loss: 0.3039 - val_accuracy: 0.9014 - lr: 1.5625e-07\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1383 - accuracy: 0.9566 - val_loss: 0.3024 - val_accuracy: 0.9014 - lr: 1.5625e-07\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1269 - accuracy: 0.9608 - val_loss: 0.3032 - val_accuracy: 0.9014 - lr: 1.5625e-07\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.1241 - accuracy: 0.9615 - val_loss: 0.3048 - val_accuracy: 0.9014 - lr: 1.5625e-07\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1119 - accuracy: 0.9601 - val_loss: 0.3049 - val_accuracy: 0.9041 - lr: 1.5625e-07\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1201 - accuracy: 0.9640 - val_loss: 0.3047 - val_accuracy: 0.9041 - lr: 1.5625e-07\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1206 - accuracy: 0.9642 - val_loss: 0.3065 - val_accuracy: 0.9014 - lr: 1.5625e-07\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1272 - accuracy: 0.9546 - val_loss: 0.3047 - val_accuracy: 0.9014 - lr: 7.8125e-08\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1474 - accuracy: 0.9525 - val_loss: 0.3056 - val_accuracy: 0.9014 - lr: 7.8125e-08\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.1399 - accuracy: 0.9525 - val_loss: 0.3053 - val_accuracy: 0.9014 - lr: 7.8125e-08\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.1153 - accuracy: 0.9615 - val_loss: 0.3069 - val_accuracy: 0.9041 - lr: 7.8125e-08\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.1289 - accuracy: 0.9553 - val_loss: 0.3060 - val_accuracy: 0.9014 - lr: 7.8125e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb3d3e1640>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=73,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/Fourth_train\"), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5df7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c32a5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/Fourth_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a5f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2 일부\n",
    "for layer in model.layers[29:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f5783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.8026 - accuracy: 0.6862 - val_loss: 6.7080 - val_accuracy: 0.0712 - lr: 1.0000e-05\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.5204 - accuracy: 0.8080 - val_loss: 7.6167 - val_accuracy: 0.0740 - lr: 1.0000e-05\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4372 - accuracy: 0.8390 - val_loss: 5.6355 - val_accuracy: 0.1041 - lr: 1.0000e-05\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3651 - accuracy: 0.8692 - val_loss: 5.0709 - val_accuracy: 0.1507 - lr: 1.0000e-05\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3818 - accuracy: 0.8527 - val_loss: 3.3986 - val_accuracy: 0.2521 - lr: 1.0000e-05\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.3102 - accuracy: 0.8920 - val_loss: 1.2292 - val_accuracy: 0.5479 - lr: 1.0000e-05\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.3020 - accuracy: 0.8906 - val_loss: 0.4731 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2946 - accuracy: 0.8906 - val_loss: 0.4371 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2536 - accuracy: 0.9069 - val_loss: 0.4046 - val_accuracy: 0.8466 - lr: 1.0000e-05\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2287 - accuracy: 0.9178 - val_loss: 0.4447 - val_accuracy: 0.8329 - lr: 1.0000e-05\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2367 - accuracy: 0.9119 - val_loss: 0.4561 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2103 - accuracy: 0.9277 - val_loss: 0.4031 - val_accuracy: 0.8493 - lr: 1.0000e-05\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2227 - accuracy: 0.9264 - val_loss: 0.4030 - val_accuracy: 0.8493 - lr: 1.0000e-05\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 45s 967ms/step - loss: 0.1976 - accuracy: 0.9229 - val_loss: 0.4123 - val_accuracy: 0.8548 - lr: 1.0000e-05\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 45s 970ms/step - loss: 0.1878 - accuracy: 0.9346 - val_loss: 0.4120 - val_accuracy: 0.8575 - lr: 1.0000e-05\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 45s 983ms/step - loss: 0.1737 - accuracy: 0.9382 - val_loss: 0.4375 - val_accuracy: 0.8438 - lr: 1.0000e-05\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 45s 969ms/step - loss: 0.1870 - accuracy: 0.9257 - val_loss: 0.4637 - val_accuracy: 0.8384 - lr: 1.0000e-05\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 0.1742 - accuracy: 0.9429 - val_loss: 0.4801 - val_accuracy: 0.8301 - lr: 5.0000e-06\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 45s 969ms/step - loss: 0.1800 - accuracy: 0.9387 - val_loss: 0.4333 - val_accuracy: 0.8521 - lr: 5.0000e-06\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.1484 - accuracy: 0.9490 - val_loss: 0.4155 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 45s 969ms/step - loss: 0.1397 - accuracy: 0.9484 - val_loss: 0.4260 - val_accuracy: 0.8630 - lr: 5.0000e-06\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 45s 970ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.4032 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 45s 970ms/step - loss: 0.1256 - accuracy: 0.9587 - val_loss: 0.4089 - val_accuracy: 0.8630 - lr: 2.5000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fae12a2f40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/Fifth_train\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b9dc2",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d4e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cb452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bdd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./logs/4th_train_aug+scheduler/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeaa466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 50s 1s/step - loss: 1.1895 - accuracy: 0.4611 - val_loss: 6.6701 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 1.0487 - accuracy: 0.5671 - val_loss: 7.4172 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.9380 - accuracy: 0.6228 - val_loss: 8.0459 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.8391 - accuracy: 0.6724 - val_loss: 8.4465 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.7156 - accuracy: 0.7426 - val_loss: 8.6580 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.6344 - accuracy: 0.7688 - val_loss: 8.0250 - val_accuracy: 0.2822 - lr: 1.0000e-05\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.5540 - accuracy: 0.7942 - val_loss: 7.1686 - val_accuracy: 0.2877 - lr: 5.0000e-06\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.5524 - accuracy: 0.8011 - val_loss: 5.9438 - val_accuracy: 0.3260 - lr: 5.0000e-06\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4909 - accuracy: 0.8240 - val_loss: 4.8906 - val_accuracy: 0.3699 - lr: 5.0000e-06\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.4594 - accuracy: 0.8410 - val_loss: 3.6988 - val_accuracy: 0.4438 - lr: 5.0000e-06\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.4398 - accuracy: 0.8548 - val_loss: 2.6288 - val_accuracy: 0.4986 - lr: 5.0000e-06\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.4424 - accuracy: 0.8479 - val_loss: 1.7573 - val_accuracy: 0.5726 - lr: 5.0000e-06\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.4193 - accuracy: 0.8513 - val_loss: 1.0815 - val_accuracy: 0.7233 - lr: 5.0000e-06\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.3939 - accuracy: 0.8679 - val_loss: 0.7290 - val_accuracy: 0.7890 - lr: 5.0000e-06\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.3566 - accuracy: 0.8754 - val_loss: 0.5907 - val_accuracy: 0.8137 - lr: 5.0000e-06\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3459 - accuracy: 0.8802 - val_loss: 0.5473 - val_accuracy: 0.8384 - lr: 5.0000e-06\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.3591 - accuracy: 0.8775 - val_loss: 0.4892 - val_accuracy: 0.8384 - lr: 5.0000e-06\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.3514 - accuracy: 0.8754 - val_loss: 0.4971 - val_accuracy: 0.8411 - lr: 5.0000e-06\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3119 - accuracy: 0.8954 - val_loss: 0.4695 - val_accuracy: 0.8466 - lr: 5.0000e-06\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.3256 - accuracy: 0.8816 - val_loss: 0.5161 - val_accuracy: 0.8301 - lr: 5.0000e-06\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.3324 - accuracy: 0.8816 - val_loss: 0.4465 - val_accuracy: 0.8466 - lr: 5.0000e-06\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.3046 - accuracy: 0.8906 - val_loss: 0.4502 - val_accuracy: 0.8603 - lr: 5.0000e-06\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.2879 - accuracy: 0.8995 - val_loss: 0.4506 - val_accuracy: 0.8630 - lr: 5.0000e-06\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.2922 - accuracy: 0.8919 - val_loss: 0.4453 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3031 - accuracy: 0.8995 - val_loss: 0.4359 - val_accuracy: 0.8630 - lr: 5.0000e-06\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.2856 - accuracy: 0.9030 - val_loss: 0.4097 - val_accuracy: 0.8767 - lr: 5.0000e-06\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.2772 - accuracy: 0.9016 - val_loss: 0.4298 - val_accuracy: 0.8548 - lr: 5.0000e-06\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.2948 - accuracy: 0.8940 - val_loss: 0.4126 - val_accuracy: 0.8630 - lr: 5.0000e-06\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2638 - accuracy: 0.9071 - val_loss: 0.4020 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2672 - accuracy: 0.9119 - val_loss: 0.3885 - val_accuracy: 0.8603 - lr: 5.0000e-06\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2469 - accuracy: 0.9137 - val_loss: 0.4052 - val_accuracy: 0.8685 - lr: 5.0000e-06\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.2610 - accuracy: 0.9035 - val_loss: 0.4167 - val_accuracy: 0.8795 - lr: 5.0000e-06\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.2449 - accuracy: 0.9164 - val_loss: 0.4051 - val_accuracy: 0.8712 - lr: 5.0000e-06\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.2408 - accuracy: 0.9198 - val_loss: 0.4060 - val_accuracy: 0.8603 - lr: 5.0000e-06\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.2200 - accuracy: 0.9246 - val_loss: 0.4165 - val_accuracy: 0.8740 - lr: 5.0000e-06\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.2207 - accuracy: 0.9257 - val_loss: 0.4118 - val_accuracy: 0.8685 - lr: 2.5000e-06\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.2258 - accuracy: 0.9188 - val_loss: 0.3968 - val_accuracy: 0.8849 - lr: 2.5000e-06\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.2060 - accuracy: 0.9305 - val_loss: 0.3919 - val_accuracy: 0.8795 - lr: 2.5000e-06\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.2010 - accuracy: 0.9293 - val_loss: 0.3904 - val_accuracy: 0.8767 - lr: 2.5000e-06\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.1925 - accuracy: 0.9339 - val_loss: 0.3745 - val_accuracy: 0.8767 - lr: 2.5000e-06\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.2057 - accuracy: 0.9307 - val_loss: 0.3802 - val_accuracy: 0.8767 - lr: 2.5000e-06\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.2045 - accuracy: 0.9327 - val_loss: 0.3798 - val_accuracy: 0.8740 - lr: 2.5000e-06\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1948 - accuracy: 0.9332 - val_loss: 0.3652 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1963 - accuracy: 0.9326 - val_loss: 0.3631 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 45s 983ms/step - loss: 0.2027 - accuracy: 0.9305 - val_loss: 0.3696 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1892 - accuracy: 0.9394 - val_loss: 0.3726 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1913 - accuracy: 0.9367 - val_loss: 0.3652 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.1782 - accuracy: 0.9456 - val_loss: 0.3794 - val_accuracy: 0.8767 - lr: 2.5000e-06\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.1807 - accuracy: 0.9387 - val_loss: 0.3731 - val_accuracy: 0.8822 - lr: 2.5000e-06\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1743 - accuracy: 0.9387 - val_loss: 0.3742 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.1812 - accuracy: 0.9408 - val_loss: 0.3713 - val_accuracy: 0.8849 - lr: 1.2500e-06\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1674 - accuracy: 0.9456 - val_loss: 0.3712 - val_accuracy: 0.8877 - lr: 1.2500e-06\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.1946 - accuracy: 0.9312 - val_loss: 0.3739 - val_accuracy: 0.8849 - lr: 1.2500e-06\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1630 - accuracy: 0.9456 - val_loss: 0.3748 - val_accuracy: 0.8795 - lr: 1.2500e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211e846a2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import train\n",
    "from model.Model import Model\n",
    "from tensorflow import keras\n",
    "from utils.utils import DataGenerator\n",
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/5th_train_aug+scheduler\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc121a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from model.callbacks import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "477c21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./logs/5th_train_aug+scheduler/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30a3ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.1881 - accuracy: 0.9375 - val_loss: 0.3701 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1717 - accuracy: 0.9443 - val_loss: 0.3669 - val_accuracy: 0.8740 - lr: 1.2500e-06\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 0.1868 - accuracy: 0.9367 - val_loss: 0.3682 - val_accuracy: 0.8822 - lr: 1.2500e-06\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 0.1694 - accuracy: 0.9408 - val_loss: 0.3708 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.2014 - accuracy: 0.9270 - val_loss: 0.3678 - val_accuracy: 0.8849 - lr: 1.2500e-06\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1719 - accuracy: 0.9395 - val_loss: 0.3640 - val_accuracy: 0.8849 - lr: 1.2500e-06\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1853 - accuracy: 0.9387 - val_loss: 0.3600 - val_accuracy: 0.8877 - lr: 1.2500e-06\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.1754 - accuracy: 0.9415 - val_loss: 0.3633 - val_accuracy: 0.8877 - lr: 1.2500e-06\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.1674 - accuracy: 0.9408 - val_loss: 0.3718 - val_accuracy: 0.8822 - lr: 1.2500e-06\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.1902 - accuracy: 0.9367 - val_loss: 0.3689 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1922 - accuracy: 0.9374 - val_loss: 0.3686 - val_accuracy: 0.8795 - lr: 1.2500e-06\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.1793 - accuracy: 0.9375 - val_loss: 0.3710 - val_accuracy: 0.8767 - lr: 1.2500e-06\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.1882 - accuracy: 0.9353 - val_loss: 0.3703 - val_accuracy: 0.8795 - lr: 6.2500e-07\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1837 - accuracy: 0.9360 - val_loss: 0.3755 - val_accuracy: 0.8849 - lr: 6.2500e-07\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.1611 - accuracy: 0.9484 - val_loss: 0.3721 - val_accuracy: 0.8822 - lr: 6.2500e-07\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.1612 - accuracy: 0.9436 - val_loss: 0.3737 - val_accuracy: 0.8822 - lr: 6.2500e-07\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1659 - accuracy: 0.9449 - val_loss: 0.3752 - val_accuracy: 0.8822 - lr: 6.2500e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211b5256580>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1.2500e-06),\n",
    "      dir_name = \"./logs/6th_train_aug+scheduler\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5b7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/4th_train_aug/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db005595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "46/46 [==============================] - 49s 1s/step - loss: 1.1278 - accuracy: 0.5272 - val_loss: 7.2086 - val_accuracy: 0.2822\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 1.0199 - accuracy: 0.5850 - val_loss: 7.9115 - val_accuracy: 0.2822\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.9101 - accuracy: 0.6318 - val_loss: 8.3260 - val_accuracy: 0.2822\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.8052 - accuracy: 0.6930 - val_loss: 8.5232 - val_accuracy: 0.2822\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.7229 - accuracy: 0.7276 - val_loss: 8.5551 - val_accuracy: 0.2822\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.6326 - accuracy: 0.7674 - val_loss: 7.6933 - val_accuracy: 0.2822\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.5796 - accuracy: 0.7825 - val_loss: 6.4651 - val_accuracy: 0.2822\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.5357 - accuracy: 0.8094 - val_loss: 5.7623 - val_accuracy: 0.3260\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.4627 - accuracy: 0.8383 - val_loss: 4.7412 - val_accuracy: 0.3699\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.4454 - accuracy: 0.8355 - val_loss: 3.4410 - val_accuracy: 0.4548\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4071 - accuracy: 0.8596 - val_loss: 2.1738 - val_accuracy: 0.5479\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.4165 - accuracy: 0.8706 - val_loss: 1.5871 - val_accuracy: 0.6466\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.3939 - accuracy: 0.8596 - val_loss: 1.1220 - val_accuracy: 0.7123\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.7641 - val_accuracy: 0.7836\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.3626 - accuracy: 0.8699 - val_loss: 0.4877 - val_accuracy: 0.8575\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.3347 - accuracy: 0.8864 - val_loss: 0.4858 - val_accuracy: 0.8575\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3273 - accuracy: 0.8885 - val_loss: 0.4717 - val_accuracy: 0.8548\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3197 - accuracy: 0.8851 - val_loss: 0.4058 - val_accuracy: 0.8904\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.2643 - accuracy: 0.9036 - val_loss: 0.3750 - val_accuracy: 0.8795\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.2850 - accuracy: 0.8954 - val_loss: 0.3840 - val_accuracy: 0.8849\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2592 - accuracy: 0.9164 - val_loss: 0.3664 - val_accuracy: 0.8795\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.2573 - accuracy: 0.9096 - val_loss: 0.3814 - val_accuracy: 0.8849\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.2586 - accuracy: 0.9064 - val_loss: 0.3678 - val_accuracy: 0.8849\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.2554 - accuracy: 0.9085 - val_loss: 0.4000 - val_accuracy: 0.8767\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.2216 - accuracy: 0.9270 - val_loss: 0.3414 - val_accuracy: 0.8904\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.2419 - accuracy: 0.9098 - val_loss: 0.3623 - val_accuracy: 0.8877\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.2140 - accuracy: 0.9229 - val_loss: 0.3435 - val_accuracy: 0.8986\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.2316 - accuracy: 0.9202 - val_loss: 0.3837 - val_accuracy: 0.8904\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1963 - accuracy: 0.9257 - val_loss: 0.3441 - val_accuracy: 0.9068\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.1838 - accuracy: 0.9382 - val_loss: 0.3483 - val_accuracy: 0.8959\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.1746 - accuracy: 0.9394 - val_loss: 0.3346 - val_accuracy: 0.8932\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.3548 - val_accuracy: 0.8877\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1654 - accuracy: 0.9463 - val_loss: 0.3302 - val_accuracy: 0.9041\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.2064 - accuracy: 0.9264 - val_loss: 0.3266 - val_accuracy: 0.9041\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1660 - accuracy: 0.9470 - val_loss: 0.3653 - val_accuracy: 0.9123\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.1604 - accuracy: 0.9477 - val_loss: 0.3503 - val_accuracy: 0.8932\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.1622 - accuracy: 0.9408 - val_loss: 0.3426 - val_accuracy: 0.8932\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1457 - accuracy: 0.9545 - val_loss: 0.3673 - val_accuracy: 0.8795\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.1398 - accuracy: 0.9532 - val_loss: 0.3472 - val_accuracy: 0.8904\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1354 - accuracy: 0.9573 - val_loss: 0.3563 - val_accuracy: 0.8986\n",
      "Epoch 52/500\n",
      "15/46 [========>.....................] - ETA: 23s - loss: 0.1054 - accuracy: 0.9646"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6876/429610245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=11,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/4th_train_aug\"), batch_size = 32)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=11,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/4th_train_aug\"), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06d32ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/4th_train_aug/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e15c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[7:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d090ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 50s 1s/step - loss: 3.1150 - accuracy: 0.4756 - val_loss: 38.6872 - val_accuracy: 0.0493\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.7002 - accuracy: 0.7564 - val_loss: 20.8975 - val_accuracy: 0.2822\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4411 - accuracy: 0.8478 - val_loss: 10.0397 - val_accuracy: 0.2822\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.3782 - accuracy: 0.8685 - val_loss: 5.0419 - val_accuracy: 0.2822\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.3584 - accuracy: 0.8768 - val_loss: 4.3592 - val_accuracy: 0.2822\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.2664 - accuracy: 0.9098 - val_loss: 3.6873 - val_accuracy: 0.2822\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 0.2683 - accuracy: 0.9126 - val_loss: 3.6355 - val_accuracy: 0.2822\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.2188 - accuracy: 0.9229 - val_loss: 3.2847 - val_accuracy: 0.2822\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.1934 - accuracy: 0.9236 - val_loss: 3.3052 - val_accuracy: 0.2822\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1909 - accuracy: 0.9312 - val_loss: 3.6131 - val_accuracy: 0.2822\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.1784 - accuracy: 0.9387 - val_loss: 3.5653 - val_accuracy: 0.2822\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.1751 - accuracy: 0.9408 - val_loss: 3.7880 - val_accuracy: 0.2822\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.1532 - accuracy: 0.9525 - val_loss: 3.6022 - val_accuracy: 0.2822\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.1343 - accuracy: 0.9553 - val_loss: 3.5057 - val_accuracy: 0.2822\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.1540 - accuracy: 0.9491 - val_loss: 2.8630 - val_accuracy: 0.2822\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 4.2071 - val_accuracy: 0.2877\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 45s 983ms/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 4.6738 - val_accuracy: 0.3123\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.1017 - accuracy: 0.9656 - val_loss: 4.2168 - val_accuracy: 0.3918\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.1033 - accuracy: 0.9688 - val_loss: 3.1668 - val_accuracy: 0.4795\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.0698 - accuracy: 0.9796 - val_loss: 2.6425 - val_accuracy: 0.5616\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.0808 - accuracy: 0.9759 - val_loss: 1.2646 - val_accuracy: 0.7260\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.0888 - accuracy: 0.9697 - val_loss: 1.3922 - val_accuracy: 0.7014\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 45s 978ms/step - loss: 0.0776 - accuracy: 0.9752 - val_loss: 2.5235 - val_accuracy: 0.6082\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.0614 - accuracy: 0.9851 - val_loss: 1.5575 - val_accuracy: 0.6658\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 2.3962 - val_accuracy: 0.6000\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.0571 - accuracy: 0.9842 - val_loss: 0.8496 - val_accuracy: 0.7753\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0541 - accuracy: 0.9814 - val_loss: 0.7267 - val_accuracy: 0.8110\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.0757 - accuracy: 0.9780 - val_loss: 2.4920 - val_accuracy: 0.5589\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 2.3121 - val_accuracy: 0.6493\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.0567 - accuracy: 0.9835 - val_loss: 3.8372 - val_accuracy: 0.5836\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 2.7441 - val_accuracy: 0.5890\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.0506 - accuracy: 0.9862 - val_loss: 7.4171 - val_accuracy: 0.3753\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 2.9111 - val_accuracy: 0.4712\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 3.6160 - val_accuracy: 0.4822\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 0.0391 - accuracy: 0.9876 - val_loss: 2.2560 - val_accuracy: 0.5945\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 0.5592 - val_accuracy: 0.8438\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 2.5404 - val_accuracy: 0.6110\n",
      "Epoch 38/500\n",
      "12/46 [======>.......................] - ETA: 26s - loss: 0.0289 - accuracy: 0.9922"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6876/3343342821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n\u001b[0m\u001b[0;32m      2\u001b[0m       dir_name = \"./logs/5th_train_aug\", model_name = \"model.h5\", batch_size=32, patience = 10)\n",
      "\u001b[1;32mc:\\Users\\yongjin\\Desktop\\work\\machin_9team\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, optimizer, dir_name, model_name, batch_size, patience)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     history = model.fit(train_generator, epochs=epochs, steps_per_epoch=46, \n\u001b[0m\u001b[0;32m     29\u001b[0m                     validation_data = validation_generator, validation_steps=12, callbacks=callbacks(dir_name, model_name, patience))\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/5th_train_aug\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-8),\n",
    "      dir_name = \"./logs/5th_train_aug\", model_name = \"model.h5\", batch_size=32, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f10929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/4th_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e927c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongjin\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.1995 - accuracy: 0.9354 - val_loss: 0.3069 - val_accuracy: 0.9041\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.1706 - accuracy: 0.9457 - val_loss: 0.3068 - val_accuracy: 0.9205\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1556 - accuracy: 0.9485 - val_loss: 0.3243 - val_accuracy: 0.9151\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1774 - accuracy: 0.9478 - val_loss: 0.3339 - val_accuracy: 0.9014\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.1447 - accuracy: 0.9471 - val_loss: 0.3503 - val_accuracy: 0.9041\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1432 - accuracy: 0.9499 - val_loss: 0.3820 - val_accuracy: 0.9014\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1331 - accuracy: 0.9560 - val_loss: 0.3815 - val_accuracy: 0.9041\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.1331 - accuracy: 0.9588 - val_loss: 0.3633 - val_accuracy: 0.9068\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1340 - accuracy: 0.9588 - val_loss: 0.4176 - val_accuracy: 0.8959\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1299 - accuracy: 0.9505 - val_loss: 0.3772 - val_accuracy: 0.9068\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.1149 - accuracy: 0.9643 - val_loss: 0.4321 - val_accuracy: 0.8959\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1201 - accuracy: 0.9650 - val_loss: 0.4099 - val_accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x268cf006f40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=35,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/4th_train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a9bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/4th_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65dae55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongjin\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "46/46 [==============================] - 61s 1s/step - loss: 0.3469 - accuracy: 0.8637 - val_loss: 0.4193 - val_accuracy: 0.8603\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.2730 - accuracy: 0.9062 - val_loss: 0.3447 - val_accuracy: 0.9041\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 46s 992ms/step - loss: 0.2019 - accuracy: 0.9394 - val_loss: 0.3288 - val_accuracy: 0.9014\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.1888 - accuracy: 0.9332 - val_loss: 0.3347 - val_accuracy: 0.9096\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1937 - accuracy: 0.9284 - val_loss: 0.3694 - val_accuracy: 0.9014\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.1922 - accuracy: 0.9360 - val_loss: 0.3586 - val_accuracy: 0.8986\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.1763 - accuracy: 0.9387 - val_loss: 0.3564 - val_accuracy: 0.9014\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 45s 976ms/step - loss: 0.1474 - accuracy: 0.9484 - val_loss: 0.3386 - val_accuracy: 0.8986\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.1349 - accuracy: 0.9573 - val_loss: 0.3394 - val_accuracy: 0.9068\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 45s 972ms/step - loss: 0.1093 - accuracy: 0.9608 - val_loss: 0.3931 - val_accuracy: 0.8822\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1134 - accuracy: 0.9599 - val_loss: 0.3901 - val_accuracy: 0.8849\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.1201 - accuracy: 0.9560 - val_loss: 0.4081 - val_accuracy: 0.8849\n",
      "Epoch 60/500\n",
      "11/46 [======>.......................] - ETA: 27s - loss: 0.1066 - accuracy: 0.9631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8288/238806141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=47,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/4th_train\"))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=47,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/4th_train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a8ba0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/4th_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fea831b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 conv1_pad\n",
      "2 conv1_conv\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 pool1_pad\n",
      "6 pool1_pool\n",
      "7 conv2_block1_1_conv\n",
      "8 conv2_block1_1_bn\n",
      "9 conv2_block1_1_relu\n",
      "10 conv2_block1_2_conv\n",
      "11 conv2_block1_2_bn\n",
      "12 conv2_block1_2_relu\n",
      "13 conv2_block1_0_conv\n",
      "14 conv2_block1_3_conv\n",
      "15 conv2_block1_0_bn\n",
      "16 conv2_block1_3_bn\n",
      "17 conv2_block1_add\n",
      "18 conv2_block1_out\n",
      "19 conv2_block2_1_conv\n",
      "20 conv2_block2_1_bn\n",
      "21 conv2_block2_1_relu\n",
      "22 conv2_block2_2_conv\n",
      "23 conv2_block2_2_bn\n",
      "24 conv2_block2_2_relu\n",
      "25 conv2_block2_3_conv\n",
      "26 conv2_block2_3_bn\n",
      "27 conv2_block2_add\n",
      "28 conv2_block2_out\n",
      "29 conv2_block3_1_conv\n",
      "30 conv2_block3_1_bn\n",
      "31 conv2_block3_1_relu\n",
      "32 conv2_block3_2_conv\n",
      "33 conv2_block3_2_bn\n",
      "34 conv2_block3_2_relu\n",
      "35 conv2_block3_3_conv\n",
      "36 conv2_block3_3_bn\n",
      "37 conv2_block3_add\n",
      "38 conv2_block3_out\n",
      "39 conv3_block1_1_conv\n",
      "40 conv3_block1_1_bn\n",
      "41 conv3_block1_1_relu\n",
      "42 conv3_block1_2_conv\n",
      "43 conv3_block1_2_bn\n",
      "44 conv3_block1_2_relu\n",
      "45 conv3_block1_0_conv\n",
      "46 conv3_block1_3_conv\n",
      "47 conv3_block1_0_bn\n",
      "48 conv3_block1_3_bn\n",
      "49 conv3_block1_add\n",
      "50 conv3_block1_out\n",
      "51 conv3_block2_1_conv\n",
      "52 conv3_block2_1_bn\n",
      "53 conv3_block2_1_relu\n",
      "54 conv3_block2_2_conv\n",
      "55 conv3_block2_2_bn\n",
      "56 conv3_block2_2_relu\n",
      "57 conv3_block2_3_conv\n",
      "58 conv3_block2_3_bn\n",
      "59 conv3_block2_add\n",
      "60 conv3_block2_out\n",
      "61 conv3_block3_1_conv\n",
      "62 conv3_block3_1_bn\n",
      "63 conv3_block3_1_relu\n",
      "64 conv3_block3_2_conv\n",
      "65 conv3_block3_2_bn\n",
      "66 conv3_block3_2_relu\n",
      "67 conv3_block3_3_conv\n",
      "68 conv3_block3_3_bn\n",
      "69 conv3_block3_add\n",
      "70 conv3_block3_out\n",
      "71 conv3_block4_1_conv\n",
      "72 conv3_block4_1_bn\n",
      "73 conv3_block4_1_relu\n",
      "74 conv3_block4_2_conv\n",
      "75 conv3_block4_2_bn\n",
      "76 conv3_block4_2_relu\n",
      "77 conv3_block4_3_conv\n",
      "78 conv3_block4_3_bn\n",
      "79 conv3_block4_add\n",
      "80 conv3_block4_out\n",
      "81 conv4_block1_1_conv\n",
      "82 conv4_block1_1_bn\n",
      "83 conv4_block1_1_relu\n",
      "84 conv4_block1_2_conv\n",
      "85 conv4_block1_2_bn\n",
      "86 conv4_block1_2_relu\n",
      "87 conv4_block1_0_conv\n",
      "88 conv4_block1_3_conv\n",
      "89 conv4_block1_0_bn\n",
      "90 conv4_block1_3_bn\n",
      "91 conv4_block1_add\n",
      "92 conv4_block1_out\n",
      "93 conv4_block2_1_conv\n",
      "94 conv4_block2_1_bn\n",
      "95 conv4_block2_1_relu\n",
      "96 conv4_block2_2_conv\n",
      "97 conv4_block2_2_bn\n",
      "98 conv4_block2_2_relu\n",
      "99 conv4_block2_3_conv\n",
      "100 conv4_block2_3_bn\n",
      "101 conv4_block2_add\n",
      "102 conv4_block2_out\n",
      "103 conv4_block3_1_conv\n",
      "104 conv4_block3_1_bn\n",
      "105 conv4_block3_1_relu\n",
      "106 conv4_block3_2_conv\n",
      "107 conv4_block3_2_bn\n",
      "108 conv4_block3_2_relu\n",
      "109 conv4_block3_3_conv\n",
      "110 conv4_block3_3_bn\n",
      "111 conv4_block3_add\n",
      "112 conv4_block3_out\n",
      "113 conv4_block4_1_conv\n",
      "114 conv4_block4_1_bn\n",
      "115 conv4_block4_1_relu\n",
      "116 conv4_block4_2_conv\n",
      "117 conv4_block4_2_bn\n",
      "118 conv4_block4_2_relu\n",
      "119 conv4_block4_3_conv\n",
      "120 conv4_block4_3_bn\n",
      "121 conv4_block4_add\n",
      "122 conv4_block4_out\n",
      "123 conv4_block5_1_conv\n",
      "124 conv4_block5_1_bn\n",
      "125 conv4_block5_1_relu\n",
      "126 conv4_block5_2_conv\n",
      "127 conv4_block5_2_bn\n",
      "128 conv4_block5_2_relu\n",
      "129 conv4_block5_3_conv\n",
      "130 conv4_block5_3_bn\n",
      "131 conv4_block5_add\n",
      "132 conv4_block5_out\n",
      "133 conv4_block6_1_conv\n",
      "134 conv4_block6_1_bn\n",
      "135 conv4_block6_1_relu\n",
      "136 conv4_block6_2_conv\n",
      "137 conv4_block6_2_bn\n",
      "138 conv4_block6_2_relu\n",
      "139 conv4_block6_3_conv\n",
      "140 conv4_block6_3_bn\n",
      "141 conv4_block6_add\n",
      "142 conv4_block6_out\n",
      "143 conv5_block1_1_conv\n",
      "144 conv5_block1_1_bn\n",
      "145 conv5_block1_1_relu\n",
      "146 conv5_block1_2_conv\n",
      "147 conv5_block1_2_bn\n",
      "148 conv5_block1_2_relu\n",
      "149 conv5_block1_0_conv\n",
      "150 conv5_block1_3_conv\n",
      "151 conv5_block1_0_bn\n",
      "152 conv5_block1_3_bn\n",
      "153 conv5_block1_add\n",
      "154 conv5_block1_out\n",
      "155 conv5_block2_1_conv\n",
      "156 conv5_block2_1_bn\n",
      "157 conv5_block2_1_relu\n",
      "158 conv5_block2_2_conv\n",
      "159 conv5_block2_2_bn\n",
      "160 conv5_block2_2_relu\n",
      "161 conv5_block2_3_conv\n",
      "162 conv5_block2_3_bn\n",
      "163 conv5_block2_add\n",
      "164 conv5_block2_out\n",
      "165 conv5_block3_1_conv\n",
      "166 conv5_block3_1_bn\n",
      "167 conv5_block3_1_relu\n",
      "168 conv5_block3_2_conv\n",
      "169 conv5_block3_2_bn\n",
      "170 conv5_block3_2_relu\n",
      "171 conv5_block3_3_conv\n",
      "172 conv5_block3_3_bn\n",
      "173 conv5_block3_add\n",
      "174 conv5_block3_out\n",
      "175 global_average_pooling2d_1\n",
      "176 dense_1\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef09743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[29:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5efdd884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 50s 1s/step - loss: 1.0168 - accuracy: 0.6587 - val_loss: 1.4942 - val_accuracy: 0.6027\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.5856 - accuracy: 0.7816 - val_loss: 2.2484 - val_accuracy: 0.5123\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.5132 - accuracy: 0.8098 - val_loss: 2.5993 - val_accuracy: 0.5288\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 45s 986ms/step - loss: 0.4292 - accuracy: 0.8530 - val_loss: 2.3233 - val_accuracy: 0.5616\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 45s 983ms/step - loss: 0.3774 - accuracy: 0.8592 - val_loss: 1.7929 - val_accuracy: 0.6521\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 0.3636 - accuracy: 0.8626 - val_loss: 1.1927 - val_accuracy: 0.7479\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3360 - accuracy: 0.8784 - val_loss: 0.7179 - val_accuracy: 0.8301\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3230 - accuracy: 0.8839 - val_loss: 0.6130 - val_accuracy: 0.8384\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3206 - accuracy: 0.8880 - val_loss: 0.5489 - val_accuracy: 0.8466\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3077 - accuracy: 0.8826 - val_loss: 0.5104 - val_accuracy: 0.8493\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2689 - accuracy: 0.9059 - val_loss: 0.4505 - val_accuracy: 0.8603\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.2600 - accuracy: 0.9087 - val_loss: 0.4959 - val_accuracy: 0.8712\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.2293 - accuracy: 0.9169 - val_loss: 0.4744 - val_accuracy: 0.8658\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2352 - accuracy: 0.9148 - val_loss: 0.4478 - val_accuracy: 0.8712\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.2338 - accuracy: 0.9231 - val_loss: 0.4745 - val_accuracy: 0.8740\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.2127 - accuracy: 0.9224 - val_loss: 0.4673 - val_accuracy: 0.8712\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2063 - accuracy: 0.9286 - val_loss: 0.4187 - val_accuracy: 0.8740\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.2006 - accuracy: 0.9341 - val_loss: 0.4503 - val_accuracy: 0.8658\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1911 - accuracy: 0.9334 - val_loss: 0.4119 - val_accuracy: 0.8795\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 0.2036 - accuracy: 0.9224 - val_loss: 0.4308 - val_accuracy: 0.8740\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1651 - accuracy: 0.9409 - val_loss: 0.4406 - val_accuracy: 0.8712\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.1612 - accuracy: 0.9478 - val_loss: 0.4649 - val_accuracy: 0.8685\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1533 - accuracy: 0.9471 - val_loss: 0.3759 - val_accuracy: 0.8904\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1518 - accuracy: 0.9451 - val_loss: 0.4594 - val_accuracy: 0.8849\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 0.1596 - accuracy: 0.9409 - val_loss: 0.4124 - val_accuracy: 0.8877\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.1579 - accuracy: 0.9485 - val_loss: 0.4090 - val_accuracy: 0.8877\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1636 - accuracy: 0.9464 - val_loss: 0.3461 - val_accuracy: 0.9068\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.1286 - accuracy: 0.9505 - val_loss: 0.3901 - val_accuracy: 0.8986\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.1470 - accuracy: 0.9519 - val_loss: 0.3787 - val_accuracy: 0.9068\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1356 - accuracy: 0.9574 - val_loss: 0.3181 - val_accuracy: 0.9041\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.3885 - val_accuracy: 0.8822\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.1132 - accuracy: 0.9629 - val_loss: 0.3835 - val_accuracy: 0.8877\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.1162 - accuracy: 0.9581 - val_loss: 0.3611 - val_accuracy: 0.8986\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1093 - accuracy: 0.9698 - val_loss: 0.3383 - val_accuracy: 0.9096\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.1073 - accuracy: 0.9657 - val_loss: 0.3768 - val_accuracy: 0.8986\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.1007 - accuracy: 0.9691 - val_loss: 0.3450 - val_accuracy: 0.9068\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 46s 990ms/step - loss: 0.0985 - accuracy: 0.9657 - val_loss: 0.3445 - val_accuracy: 0.9014\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 45s 981ms/step - loss: 0.1177 - accuracy: 0.9670 - val_loss: 0.3438 - val_accuracy: 0.9014\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.0959 - accuracy: 0.9691 - val_loss: 0.3445 - val_accuracy: 0.9096\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.0864 - accuracy: 0.9746 - val_loss: 0.3527 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f2b334250>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/5th_train_learning_rate1e-5\", model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8a2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./logs/5th_train_learning_rate1e-5/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54b75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de4cbfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train, valid = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59680753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303e7bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1059 - accuracy: 0.9615 - val_loss: 0.3666 - val_accuracy: 0.8932\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.1347 - accuracy: 0.9547 - val_loss: 0.3413 - val_accuracy: 0.8959\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.1195 - accuracy: 0.9560 - val_loss: 0.4054 - val_accuracy: 0.8849\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.0949 - accuracy: 0.9739 - val_loss: 0.4190 - val_accuracy: 0.8712\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.1043 - accuracy: 0.9615 - val_loss: 0.3585 - val_accuracy: 0.9096\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 45s 979ms/step - loss: 0.0908 - accuracy: 0.9670 - val_loss: 0.3693 - val_accuracy: 0.9041\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 45s 975ms/step - loss: 0.0943 - accuracy: 0.9725 - val_loss: 0.3907 - val_accuracy: 0.8986\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 45s 973ms/step - loss: 0.0844 - accuracy: 0.9746 - val_loss: 0.4075 - val_accuracy: 0.8986\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 45s 980ms/step - loss: 0.0891 - accuracy: 0.9705 - val_loss: 0.4092 - val_accuracy: 0.9041\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1167 - accuracy: 0.9602 - val_loss: 0.3689 - val_accuracy: 0.8986\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 45s 974ms/step - loss: 0.0922 - accuracy: 0.9725 - val_loss: 0.3807 - val_accuracy: 0.9014\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 45s 977ms/step - loss: 0.0929 - accuracy: 0.9650 - val_loss: 0.4087 - val_accuracy: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x268a8e8c700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=500, steps_per_epoch=46, initial_epoch=40,\n",
    "                    validation_data = valid, validation_steps=12, callbacks=callbacks(\"./logs/5th_train_learning_rate1e-5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eede2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44e84f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yongjin\\Desktop\\work\\machin_9team\\train.py:28: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=46,\n",
      "C:\\Users\\yongjin\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.6012 - accuracy: 0.8001 - val_loss: 5.0311 - val_accuracy: 0.3562\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3042 - accuracy: 0.8860 - val_loss: 4.9049 - val_accuracy: 0.3425\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.2633 - accuracy: 0.9052 - val_loss: 4.1485 - val_accuracy: 0.3726\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 46s 986ms/step - loss: 0.2656 - accuracy: 0.9100 - val_loss: 4.7481 - val_accuracy: 0.4082\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 46s 985ms/step - loss: 0.2170 - accuracy: 0.9162 - val_loss: 5.0122 - val_accuracy: 0.5151\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.1864 - accuracy: 0.9368 - val_loss: 3.1225 - val_accuracy: 0.5836\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1994 - accuracy: 0.9313 - val_loss: 1.5841 - val_accuracy: 0.6740\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.1738 - accuracy: 0.9409 - val_loss: 1.5623 - val_accuracy: 0.7014\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1808 - accuracy: 0.9327 - val_loss: 1.2636 - val_accuracy: 0.7370\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1515 - accuracy: 0.9457 - val_loss: 0.8598 - val_accuracy: 0.8137\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1525 - accuracy: 0.9505 - val_loss: 0.8445 - val_accuracy: 0.8055\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1337 - accuracy: 0.9478 - val_loss: 0.7827 - val_accuracy: 0.8384\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1467 - accuracy: 0.9485 - val_loss: 0.6391 - val_accuracy: 0.8548\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1206 - accuracy: 0.9595 - val_loss: 0.6333 - val_accuracy: 0.8630\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1126 - accuracy: 0.9554 - val_loss: 0.5598 - val_accuracy: 0.8466\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.1354 - accuracy: 0.9554 - val_loss: 0.5281 - val_accuracy: 0.8548\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 0.4562 - val_accuracy: 0.8904\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 45s 982ms/step - loss: 0.1114 - accuracy: 0.9698 - val_loss: 0.5298 - val_accuracy: 0.8658\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 46s 989ms/step - loss: 0.0810 - accuracy: 0.9739 - val_loss: 0.5533 - val_accuracy: 0.8712\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 988ms/step - loss: 0.0762 - accuracy: 0.9732 - val_loss: 0.5435 - val_accuracy: 0.8603\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.1012 - accuracy: 0.9615 - val_loss: 0.5940 - val_accuracy: 0.8603\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 46s 993ms/step - loss: 0.0982 - accuracy: 0.9629 - val_loss: 0.5092 - val_accuracy: 0.8822\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.0957 - accuracy: 0.9677 - val_loss: 0.4785 - val_accuracy: 0.8877\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 45s 984ms/step - loss: 0.0853 - accuracy: 0.9705 - val_loss: 0.5108 - val_accuracy: 0.8877\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 46s 991ms/step - loss: 0.0536 - accuracy: 0.9821 - val_loss: 0.5332 - val_accuracy: 0.8877\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.0712 - accuracy: 0.9780 - val_loss: 0.4944 - val_accuracy: 0.8959\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 46s 984ms/step - loss: 0.0968 - accuracy: 0.9677 - val_loss: 0.5274 - val_accuracy: 0.8795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f2f11feb0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      dir_name = \"./logs/6th_train_learning_rate1e-5\", model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07e4ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./logs/6th_train_learning_rate1e-5/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "945f7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[7:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18f46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 50s 1s/step - loss: 2.9155 - accuracy: 0.5144 - val_loss: 10.0998 - val_accuracy: 0.2822\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 2.8754 - accuracy: 0.5027 - val_loss: 7.7494 - val_accuracy: 0.2822\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 997ms/step - loss: 2.8345 - accuracy: 0.5062 - val_loss: 5.0081 - val_accuracy: 0.2822\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 2.7889 - accuracy: 0.5172 - val_loss: 3.4829 - val_accuracy: 0.2822\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 2.7120 - accuracy: 0.5268 - val_loss: 3.3305 - val_accuracy: 0.2822\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 2.6313 - accuracy: 0.5330 - val_loss: 3.7168 - val_accuracy: 0.2822\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 996ms/step - loss: 2.5761 - accuracy: 0.5254 - val_loss: 4.0299 - val_accuracy: 0.2822\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 2.5749 - accuracy: 0.5343 - val_loss: 4.1635 - val_accuracy: 0.2822\n",
      "Epoch 9/500\n",
      "30/46 [==================>...........] - ETA: 12s - loss: 2.6597 - accuracy: 0.5318"
     ]
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.SGD(learning_rate=5e-6),\n",
    "      dir_name = \"./logs/7th_train_learning_rate5e-6\", model_name = \"model.h5\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "915197d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./logs/5th_train/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f4f803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv 2\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5f464e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 51s 1s/step - loss: 1.5156 - accuracy: 0.5481 - val_loss: 8.0480 - val_accuracy: 0.2822\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 0.7884 - accuracy: 0.6937 - val_loss: 8.8461 - val_accuracy: 0.2822\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.6672 - accuracy: 0.7548 - val_loss: 6.2045 - val_accuracy: 0.2877\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 45s 985ms/step - loss: 0.6313 - accuracy: 0.7665 - val_loss: 6.3869 - val_accuracy: 0.2877\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.5774 - accuracy: 0.7946 - val_loss: 4.9294 - val_accuracy: 0.3370\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 46s 998ms/step - loss: 0.5549 - accuracy: 0.8008 - val_loss: 3.2552 - val_accuracy: 0.4712\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.5183 - accuracy: 0.8187 - val_loss: 2.5971 - val_accuracy: 0.5260\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.5141 - accuracy: 0.8214 - val_loss: 2.3757 - val_accuracy: 0.5507\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.5106 - accuracy: 0.8056 - val_loss: 1.9650 - val_accuracy: 0.5671\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4967 - accuracy: 0.8249 - val_loss: 1.7174 - val_accuracy: 0.5890\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4950 - accuracy: 0.8235 - val_loss: 1.5124 - val_accuracy: 0.6247\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 46s 1000ms/step - loss: 0.4973 - accuracy: 0.8304 - val_loss: 1.2598 - val_accuracy: 0.6685\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4669 - accuracy: 0.8255 - val_loss: 0.9719 - val_accuracy: 0.7233\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4712 - accuracy: 0.8297 - val_loss: 0.7821 - val_accuracy: 0.7808\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4549 - accuracy: 0.8372 - val_loss: 0.6546 - val_accuracy: 0.8055\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4334 - accuracy: 0.8427 - val_loss: 0.6160 - val_accuracy: 0.8164\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4357 - accuracy: 0.8386 - val_loss: 0.6008 - val_accuracy: 0.8247\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4366 - accuracy: 0.8420 - val_loss: 0.5764 - val_accuracy: 0.8192\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.4239 - accuracy: 0.8551 - val_loss: 0.5524 - val_accuracy: 0.8301\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.4409 - accuracy: 0.8407 - val_loss: 0.5494 - val_accuracy: 0.8356\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 46s 1s/step - loss: 0.3918 - accuracy: 0.8551 - val_loss: 0.5456 - val_accuracy: 0.8329\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 46s 994ms/step - loss: 0.3935 - accuracy: 0.8668 - val_loss: 0.5495 - val_accuracy: 0.8274\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 46s 999ms/step - loss: 0.4146 - accuracy: 0.8565 - val_loss: 0.5470 - val_accuracy: 0.8274\n",
      "Epoch 24/500\n",
      "14/46 [========>.....................] - ETA: 25s - loss: 0.3882 - accuracy: 0.8728"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14960/1572084219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-6),\n\u001b[0m\u001b[0;32m      2\u001b[0m       dir_name = \"./logs/6th_train\", model_name = \"model.h5\", batch_size=32)\n",
      "\u001b[1;32mc:\\Users\\yongjin\\Desktop\\work\\machin_9team\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, optimizer, dir_name, model_name, batch_size, patience)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     history = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=46, \n\u001b[0m\u001b[0;32m     29\u001b[0m                     validation_data = validation_generator, validation_steps=12, callbacks=callbacks(dir_name, model_name, patience))\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2016\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, epochs = 500, optimizer = keras.optimizers.Adam(learning_rate=1e-6),\n",
    "      dir_name = \"./logs/6th_train\", model_name = \"model.h5\", batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
